{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of SRGAN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "nyf7hxD04ooV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "5452a74b-102d-4c6b-cf40-82ea727bfe3a"
      },
      "source": [
        "!pip install scipy==0.19.1   #from updated versions of scipy imresize is removed\n",
        "!pip install tensorflow==1.15.0\n",
        "!pip install keras==2.2.4\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting scipy==0.19.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0e/46/da8d7166102d29695330f7c0b912955498542988542c0d2ae3ea0389c68d/scipy-0.19.1-cp36-cp36m-manylinux1_x86_64.whl (48.2MB)\n",
            "\u001b[K     |████████████████████████████████| 48.2MB 59kB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.8.2 in /usr/local/lib/python3.6/dist-packages (from scipy==0.19.1) (1.18.5)\n",
            "\u001b[31mERROR: yellowbrick 0.9.1 has requirement scipy>=1.0.0, but you'll have scipy 0.19.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: umap-learn 0.4.6 has requirement scipy>=1.3.1, but you'll have scipy 0.19.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow 2.2.0 has requirement scipy==1.4.1; python_version >= \"3\", but you'll have scipy 0.19.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: seaborn 0.10.1 has requirement scipy>=1.0.1, but you'll have scipy 0.19.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: plotnine 0.6.0 has requirement scipy>=1.2.0, but you'll have scipy 0.19.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: librosa 0.6.3 has requirement scipy>=1.0.0, but you'll have scipy 0.19.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: cvxpy 1.0.31 has requirement scipy>=1.1.0, but you'll have scipy 0.19.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Installing collected packages: scipy\n",
            "  Found existing installation: scipy 1.4.1\n",
            "    Uninstalling scipy-1.4.1:\n",
            "      Successfully uninstalled scipy-1.4.1\n",
            "Successfully installed scipy-0.19.1\n",
            "Collecting tensorflow==1.15.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3f/98/5a99af92fb911d7a88a0005ad55005f35b4c1ba8d75fba02df726cd936e6/tensorflow-1.15.0-cp36-cp36m-manylinux2010_x86_64.whl (412.3MB)\n",
            "\u001b[K     |████████████████████████████████| 412.3MB 35kB/s \n",
            "\u001b[?25hRequirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (1.0.8)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (1.1.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (0.9.0)\n",
            "Collecting tensorboard<1.16.0,>=1.15.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1e/e9/d3d747a97f7188f48aa5eda486907f3b345cd409f0a0850468ba867db246/tensorboard-1.15.0-py3-none-any.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 48.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (3.3.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (1.12.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (1.1.2)\n",
            "Collecting gast==0.2.2\n",
            "  Downloading https://files.pythonhosted.org/packages/4e/35/11749bf99b2d4e3cceb4d55ca22590b0d7c2c62b9de38ac4a4a7f4687421/gast-0.2.2.tar.gz\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (0.8.1)\n",
            "Collecting tensorflow-estimator==1.15.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/de/62/2ee9cd74c9fa2fa450877847ba560b260f5d0fb70ee0595203082dafcc9d/tensorflow_estimator-1.15.1-py2.py3-none-any.whl (503kB)\n",
            "\u001b[K     |████████████████████████████████| 512kB 67.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (1.30.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (0.34.2)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (0.2.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (3.12.2)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (1.15.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (1.18.5)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow==1.15.0) (2.10.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (3.2.2)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (49.1.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (1.0.1)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (1.7.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (3.1.0)\n",
            "Building wheels for collected packages: gast\n",
            "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gast: filename=gast-0.2.2-cp36-none-any.whl size=7540 sha256=2c1211d8f6732449872a19582149d7421a39490938dffa56d0d5a2a60f491d82\n",
            "  Stored in directory: /root/.cache/pip/wheels/5c/2e/7e/a1d4d4fcebe6c381f378ce7743a3ced3699feb89bcfbdadadd\n",
            "Successfully built gast\n",
            "\u001b[31mERROR: tensorflow-probability 0.10.0 has requirement gast>=0.3.2, but you'll have gast 0.2.2 which is incompatible.\u001b[0m\n",
            "Installing collected packages: tensorboard, gast, tensorflow-estimator, tensorflow\n",
            "  Found existing installation: tensorboard 2.2.2\n",
            "    Uninstalling tensorboard-2.2.2:\n",
            "      Successfully uninstalled tensorboard-2.2.2\n",
            "  Found existing installation: gast 0.3.3\n",
            "    Uninstalling gast-0.3.3:\n",
            "      Successfully uninstalled gast-0.3.3\n",
            "  Found existing installation: tensorflow-estimator 2.2.0\n",
            "    Uninstalling tensorflow-estimator-2.2.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.2.0\n",
            "  Found existing installation: tensorflow 2.2.0\n",
            "    Uninstalling tensorflow-2.2.0:\n",
            "      Successfully uninstalled tensorflow-2.2.0\n",
            "Successfully installed gast-0.2.2 tensorboard-1.15.0 tensorflow-1.15.0 tensorflow-estimator-1.15.1\n",
            "Collecting keras==2.2.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5e/10/aa32dad071ce52b5502266b5c659451cfd6ffcbf14e6c8c4f16c0ff5aaab/Keras-2.2.4-py2.py3-none-any.whl (312kB)\n",
            "\u001b[K     |████████████████████████████████| 317kB 3.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4) (1.15.0)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4) (1.18.5)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4) (1.0.8)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4) (1.1.2)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4) (2.10.0)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4) (0.19.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4) (3.13)\n",
            "Installing collected packages: keras\n",
            "  Found existing installation: Keras 2.3.1\n",
            "    Uninstalling Keras-2.3.1:\n",
            "      Successfully uninstalled Keras-2.3.1\n",
            "Successfully installed keras-2.2.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aw6-1FfNz3hu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7e5e2407-61ef-46e3-c5ef-12396242d948"
      },
      "source": [
        "#utils, processes images\n",
        "\n",
        "from keras.layers import Lambda\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from numpy import array\n",
        "from numpy.random import randint\n",
        "from scipy.misc import imresize\n",
        "import os\n",
        "import sys\n",
        "import imageio\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "plt.switch_backend('agg')\n",
        "\n",
        "\n",
        "\n",
        "# Subpixel Conv will upsample from (h, w, c) to (h/r, w/r, c/r^2)\n",
        "def SubpixelConv2D(input_shape, scale=4):\n",
        "    def subpixel_shape(input_shape):\n",
        "        dims = [input_shape[0],input_shape[1] * scale,input_shape[2] * scale,int(input_shape[3] / (scale ** 2))]\n",
        "        output_shape = tuple(dims)\n",
        "        return output_shape\n",
        "    \n",
        "    def subpixel(x):\n",
        "        return tf.depth_to_space(x, scale)\n",
        "        \n",
        "    return Lambda(subpixel, output_shape=subpixel_shape)\n",
        "    \n",
        "# Takes list of images and provide HR images in form of numpy array\n",
        "def hr_images(images):\n",
        "    images_hr = array(images)\n",
        "    return images_hr\n",
        "\n",
        "# Takes list of images and provide LR images in form of numpy array\n",
        "def lr_images(images_real , downscale):\n",
        "    \n",
        "    images = []\n",
        "    for img in  range(len(images_real)):\n",
        "        images.append(imresize(images_real[img], [images_real[img].shape[0]//downscale,images_real[img].shape[1]//downscale], interp='bicubic', mode=None))\n",
        "    images_lr = array(images)\n",
        "    return images_lr\n",
        "    \n",
        "def normalize(input_data):\n",
        "\n",
        "    return (input_data.astype(np.float32) - 127.5)/127.5 \n",
        "    \n",
        "def denormalize(input_data):\n",
        "    input_data = (input_data + 1) * 127.5\n",
        "    return input_data.astype(np.uint8)\n",
        "\n",
        "def load_path(path):\n",
        "    directories = []\n",
        "    if os.path.isdir(path):\n",
        "        directories.append(path)\n",
        "    for elem in os.listdir(path):\n",
        "        if os.path.isdir(os.path.join(path,elem)):\n",
        "            directories = directories + load_path(os.path.join(path,elem))\n",
        "            directories.append(os.path.join(path,elem))\n",
        "    return directories\n",
        "    \n",
        "def load_data_from_dirs(dirs, ext):\n",
        "    files = []\n",
        "    file_names = []\n",
        "    count = 0\n",
        "    for d in dirs:\n",
        "        for f in os.listdir(d): \n",
        "            if f.endswith(ext):\n",
        "                image = imageio.imread(os.path.join(d,f))\n",
        "                if len(image.shape) > 2:\n",
        "                    files.append(imresize(image, (320, 240)))\n",
        "                    file_names.append(os.path.join(d,f))\n",
        "                count = count + 1\n",
        "    return files     \n",
        "\n",
        "def load_data(directory, ext):\n",
        "\n",
        "    files = load_data_from_dirs(load_path(directory), ext)\n",
        "    return files\n",
        "\n",
        "def load_training_data(directory, ext, number_of_images = 1000, train_test_ratio = 0.8):\n",
        "\n",
        "    number_of_train_images = int(number_of_images * train_test_ratio)\n",
        "    \n",
        "    files = load_data(directory, ext)\n",
        "    \n",
        "    if len(files) < number_of_images:\n",
        "        print(\"Number of image files are less then you specified\")\n",
        "        print(\"Please reduce number of images to %d\" % len(files))\n",
        "        sys.exit()\n",
        "        \n",
        "    test_array = array(files)\n",
        "    if len(test_array.shape) < 3:\n",
        "        print(\"Images are of not same shape\")\n",
        "        print(\"Please provide same shape images\")\n",
        "        sys.exit()\n",
        "    \n",
        "    x_train = files[:number_of_train_images]\n",
        "    x_test = files[number_of_train_images:number_of_images]\n",
        "    \n",
        "    x_train_hr = hr_images(x_train)\n",
        "    x_train_hr = normalize(x_train_hr)\n",
        "    \n",
        "    x_train_lr = lr_images(x_train, 4)\n",
        "    x_train_lr = normalize(x_train_lr)\n",
        "    \n",
        "    x_test_hr = hr_images(x_test)\n",
        "    x_test_hr = normalize(x_test_hr)\n",
        "    \n",
        "    x_test_lr = lr_images(x_test, 4)\n",
        "    x_test_lr = normalize(x_test_lr)\n",
        "    \n",
        "    return x_train_lr, x_train_hr, x_test_lr, x_test_hr\n",
        "\n",
        "\n",
        "def load_test_data_for_model(directory, ext, number_of_images = 100):\n",
        "\n",
        "    files = load_data(directory, ext)\n",
        "    \n",
        "    if len(files) < number_of_images:\n",
        "        print(\"Number of image files are less then you specified\")\n",
        "        print(\"Please reduce number of images to %d\" % len(files))\n",
        "        sys.exit()\n",
        "\n",
        "    rand_nums = np.random.randint(0, files.shape[0], size=number_of_images)\n",
        "        \n",
        "    x_test_hr = hr_images(files[rand_nums])\n",
        "    x_test_hr = normalize(x_test_hr)\n",
        "    \n",
        "    x_test_lr = lr_images(files[rand_nums], 4)\n",
        "    x_test_lr = normalize(x_test_lr)\n",
        "    \n",
        "    return x_test_lr, x_test_hr\n",
        "    \n",
        "def load_test_data(directory, ext, number_of_images = 100):\n",
        "\n",
        "    files = load_data(directory, ext)\n",
        "    \n",
        "    if len(files) < number_of_images:\n",
        "        print(\"Number of image files are less then you specified\")\n",
        "        print(\"Please reduce number of images to %d\" % len(files))\n",
        "        sys.exit()\n",
        "\n",
        "    rand_nums = np.random.randint(0, files.shape[0], size=number_of_images)\n",
        "        \n",
        "    x_test_lr = lr_images(files[rand_nums], 4)\n",
        "    x_test_lr = normalize(x_test_lr)\n",
        "    \n",
        "    return x_test_lr\n",
        "    \n",
        "\n",
        "def plot_generated_images(output_dir, epoch, generator, x_test_hr, x_test_lr , dim=(1, 3), figsize=(15, 5), batch_size = 8):\n",
        "    \n",
        "    batch_count = int(x_test_hr.shape[0] / batch_size)\n",
        "\n",
        "    generated_image = []\n",
        "\n",
        "    for k in range(batch_count):\n",
        "\n",
        "      lo = batch_size*k\n",
        "      hi = batch_size*(k+1)\n",
        "      if(hi>x_test_hr.shape[0]):\n",
        "        hi = x_test_hr.shape[0]\n",
        "\n",
        "      image_batch_lr_here = x_test_lr[lo:hi]\n",
        "      gen_img = generator.predict(image_batch_lr_here)\n",
        "      generated_image.append(denormalize(gen_img))\n",
        "      #print(k, ' ', lo, ' ', hi, ' ', image_batch_lr_here.shape[0], ' ', gen_img.shape[0], ' ', len(generated_image))\n",
        "\n",
        "\n",
        "\n",
        "    examples = x_test_hr.shape[0]\n",
        "    #print(examples)\n",
        "    #print(len(generated_image))\n",
        "    value = randint(0, examples)\n",
        "    value_i = value // 8\n",
        "    value_j = value % 8\n",
        "    image_batch_hr = denormalize(x_test_hr)\n",
        "    image_batch_lr = denormalize(x_test_lr)\n",
        "    \n",
        "    plt.figure(figsize=figsize)\n",
        "    \n",
        "    plt.subplot(dim[0], dim[1], 1)\n",
        "    plt.imshow(image_batch_lr[value], interpolation='nearest')\n",
        "    plt.axis('off')\n",
        "        \n",
        "    plt.subplot(dim[0], dim[1], 2)\n",
        "    plt.imshow(generated_image[value_i][value_j], interpolation='nearest')\n",
        "    plt.axis('off')\n",
        "    \n",
        "    plt.subplot(dim[0], dim[1], 3)\n",
        "    plt.imshow(image_batch_hr[value], interpolation='nearest')\n",
        "    plt.axis('off')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.savefig(output_dir + 'generated_image_%d.png' % epoch)\n",
        "    \n",
        "    #plt.show()\n",
        "    \n",
        "\n",
        "def plot_test_generated_images_for_model(output_dir, generator, x_test_hr, x_test_lr , dim=(1, 3), figsize=(15, 5), batch_size = 8):\n",
        "    \n",
        "    batch_count = int(x_test_hr.shape[0] / batch_size)\n",
        "\n",
        "    generated_image = []\n",
        "\n",
        "    for k in range(batch_count):\n",
        "\n",
        "      lo = batch_size*k\n",
        "      hi = batch_size*(k+1)\n",
        "      if(hi>x_test_hr.shape[0]):\n",
        "        hi = x_test_hr.shape[0]\n",
        "\n",
        "      image_batch_lr_here = x_test_lr[lo:hi]\n",
        "      gen_img = generator.predict(image_batch_lr_here)\n",
        "      generated_image.append(denormalize(gen_img))\n",
        "\n",
        "    examples = x_test_hr.shape[0]\n",
        "    image_batch_hr = denormalize(x_test_hr)\n",
        "    image_batch_lr = denormalize(x_test_lr)\n",
        "    \n",
        "    for index in range(examples):\n",
        "\n",
        "        value_i = index // 8\n",
        "        value_j = index % 8\n",
        "    \n",
        "        plt.figure(figsize=figsize)\n",
        "    \n",
        "        plt.subplot(dim[0], dim[1], 1)\n",
        "        plt.imshow(image_batch_lr[index], interpolation='nearest')\n",
        "        plt.axis('off')\n",
        "        \n",
        "        plt.subplot(dim[0], dim[1], 2)\n",
        "        plt.imshow(generated_image[index_i][index_j], interpolation='nearest')\n",
        "        plt.axis('off')\n",
        "    \n",
        "        plt.subplot(dim[0], dim[1], 3)\n",
        "        plt.imshow(image_batch_hr[index], interpolation='nearest')\n",
        "        plt.axis('off')\n",
        "    \n",
        "        plt.tight_layout()\n",
        "        plt.savefig(output_dir + 'test_generated_image_%d.png' % index)\n",
        "    \n",
        "        #plt.show()\n",
        "\n",
        "\n",
        "def plot_test_generated_images(output_dir, generator, x_test_lr, figsize=(5, 5), batch_size = 8):\n",
        "    \n",
        "    batch_count = int(x_test_lr.shape[0] / batch_size)\n",
        "\n",
        "    generated_image = []\n",
        "\n",
        "    for k in range(batch_count):\n",
        "\n",
        "      lo = batch_size*k\n",
        "      hi = batch_size*(k+1)\n",
        "      if(hi>x_test_lr.shape[0]):\n",
        "        hi = x_test_lr.shape[0]\n",
        "\n",
        "      image_batch_lr_here = x_test_lr[lo:hi]\n",
        "      gen_img = generator.predict(image_batch_lr_here)\n",
        "      generated_image.append(denormalize(gen_img))\n",
        "\n",
        "\n",
        "\n",
        "    examples = x_test_lr.shape[0]\n",
        "    value = randint(0, examples)\n",
        "    image_batch_lr = denormalize(x_test_lr)\n",
        "    \n",
        "    for index in range(examples):\n",
        "\n",
        "        value_i = index // 8\n",
        "        value_j = index % 8\n",
        "    \n",
        "    \n",
        "        plt.imshow(generated_image[index_i][index_j], interpolation='nearest')\n",
        "        plt.axis('off')\n",
        "        \n",
        "        plt.tight_layout()\n",
        "        plt.savefig(output_dir + 'high_res_result_image_%d.png' % index)\n",
        "    \n",
        "   "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s4Slvr8o6ryZ"
      },
      "source": [
        "# network architecture\n",
        "\n",
        "\n",
        "from keras.layers import Dense\n",
        "from keras.layers.core import Activation\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.layers.convolutional import UpSampling2D\n",
        "from keras.layers.core import Flatten\n",
        "from keras.layers import Input\n",
        "from keras.layers.convolutional import Conv2D, Conv2DTranspose\n",
        "from keras.models import Model\n",
        "from keras.layers.advanced_activations import LeakyReLU, PReLU\n",
        "from keras.layers import add\n",
        "\n",
        "# Residual block\n",
        "def res_block_gen(model, kernal_size, filters, strides):\n",
        "    \n",
        "    gen = model\n",
        "    \n",
        "    model = Conv2D(filters = filters, kernel_size = kernal_size, strides = strides, padding = \"same\")(model)\n",
        "    model = BatchNormalization(momentum = 0.5)(model)\n",
        "    # Using Parametric ReLU\n",
        "    model = PReLU(alpha_initializer='zeros', alpha_regularizer=None, alpha_constraint=None, shared_axes=[1,2])(model)\n",
        "    model = Conv2D(filters = filters, kernel_size = kernal_size, strides = strides, padding = \"same\")(model)\n",
        "    model = BatchNormalization(momentum = 0.5)(model)\n",
        "        \n",
        "    model = add([gen, model])\n",
        "    \n",
        "    return model\n",
        "    \n",
        "    \n",
        "def up_sampling_block(model, kernal_size, filters, strides):\n",
        "    \n",
        "    model = Conv2D(filters = filters, kernel_size = kernal_size, strides = strides, padding = \"same\")(model)\n",
        "    model = UpSampling2D(size = 2)(model)\n",
        "    model = LeakyReLU(alpha = 0.2)(model)\n",
        "    \n",
        "    return model\n",
        "\n",
        "\n",
        "def discriminator_block(model, filters, kernel_size, strides):\n",
        "    \n",
        "    model = Conv2D(filters = filters, kernel_size = kernel_size, strides = strides, padding = \"same\")(model)\n",
        "    model = BatchNormalization(momentum = 0.5)(model)\n",
        "    model = LeakyReLU(alpha = 0.2)(model)\n",
        "    \n",
        "    return model\n",
        "\n",
        "class Generator(object):\n",
        "\n",
        "    def __init__(self, noise_shape):\n",
        "        \n",
        "        self.noise_shape = noise_shape\n",
        "\n",
        "    def generator(self):\n",
        "        \n",
        "\t    gen_input = Input(shape = self.noise_shape)\n",
        "\t    \n",
        "\t    model = Conv2D(filters = 64, kernel_size = 9, strides = 1, padding = \"same\")(gen_input)\n",
        "\t    model = PReLU(alpha_initializer='zeros', alpha_regularizer=None, alpha_constraint=None, shared_axes=[1,2])(model)\n",
        "\t    \n",
        "\t    gen_model = model\n",
        "        \n",
        "      # Using 16 Residual Blocks\n",
        "\t    for index in range(16):\n",
        "\t        model = res_block_gen(model, 3, 64, 1)\n",
        "\t    \n",
        "\t    model = Conv2D(filters = 64, kernel_size = 3, strides = 1, padding = \"same\")(model)\n",
        "\t    model = BatchNormalization(momentum = 0.5)(model)\n",
        "\t    model = add([gen_model, model])\n",
        "\t    \n",
        "\t    # Using 2 UpSampling Blocks\n",
        "\t    for index in range(2):\n",
        "\t        model = up_sampling_block(model, 3, 256, 1)\n",
        "\t    \n",
        "\t    model = Conv2D(filters = 3, kernel_size = 9, strides = 1, padding = \"same\")(model)\n",
        "\t    model = Activation('tanh')(model)\n",
        "\t   \n",
        "\t    generator_model = Model(inputs = gen_input, outputs = model)\n",
        "     \n",
        "        \n",
        "\t    return generator_model\n",
        "\n",
        "class Discriminator(object):\n",
        "\n",
        "    def __init__(self, image_shape):\n",
        "        \n",
        "        self.image_shape = image_shape\n",
        "    \n",
        "    def discriminator(self):\n",
        "        \n",
        "        dis_input = Input(shape = self.image_shape)\n",
        "        \n",
        "        model = Conv2D(filters = 64, kernel_size = 3, strides = 1, padding = \"same\")(dis_input)\n",
        "        model = LeakyReLU(alpha = 0.2)(model)\n",
        "        \n",
        "        model = discriminator_block(model, 64, 3, 2)\n",
        "        model = discriminator_block(model, 128, 3, 1)\n",
        "        model = discriminator_block(model, 128, 3, 2)\n",
        "        model = discriminator_block(model, 256, 3, 1)\n",
        "        model = discriminator_block(model, 256, 3, 2)\n",
        "        model = discriminator_block(model, 512, 3, 1)\n",
        "        model = discriminator_block(model, 512, 3, 2)\n",
        "        \n",
        "        model = Flatten()(model)\n",
        "        model = Dense(1024)(model)\n",
        "        model = LeakyReLU(alpha = 0.2)(model)\n",
        "       \n",
        "        model = Dense(1)(model)\n",
        "        model = Activation('sigmoid')(model) \n",
        "        \n",
        "        discriminator_model = Model(inputs = dis_input, outputs = model)\n",
        "        \n",
        "        return discriminator_model\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YMgifhCnyVcc"
      },
      "source": [
        "# optimizer, loss parameters\n",
        "\n",
        "from keras.applications.vgg19 import VGG19\n",
        "import keras.backend as K\n",
        "from keras.models import Model\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "class VGG_LOSS(object):\n",
        "\n",
        "    def __init__(self, image_shape):\n",
        "        \n",
        "        self.image_shape = image_shape\n",
        "\n",
        "    # computes VGG loss or content loss\n",
        "    def vgg_loss(self, y_true, y_pred):\n",
        "    \n",
        "        vgg19 = VGG19(include_top=False, weights='imagenet', input_shape=self.image_shape)\n",
        "        vgg19.trainable = False\n",
        "        # Make trainable as False\n",
        "        for l in vgg19.layers:\n",
        "            l.trainable = False\n",
        "        model = Model(inputs=vgg19.input, outputs=vgg19.get_layer('block5_conv4').output)\n",
        "        model.trainable = False\n",
        "    \n",
        "        return K.mean(K.square(model(y_true) - model(y_pred)))\n",
        "    \n",
        "def get_optimizer():\n",
        " \n",
        "    adam = Adam(lr=1E-4, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
        "    return adam"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8_JC1S2afD7G"
      },
      "source": [
        "# training data\n",
        "\n",
        "#from tf.compat.v1.keras.backend.set_session import set_session\n",
        "from keras.models import Model, load_model, save_model\n",
        "from keras.layers import Input\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import argparse\n",
        "\n",
        "#global sess\n",
        "#global graph\n",
        "\n",
        "np.random.seed(10)\n",
        "\n",
        "downscale_factor = 4\n",
        "# Remember to change image shape if you are having different size of images\n",
        "image_shape = (320,240,3)\n",
        "\n",
        "\n",
        "\n",
        "# Combined network\n",
        "def get_gan_network(discriminator, shape, generator, optimizer, vgg_loss):\n",
        "    discriminator.trainable = False\n",
        "    gan_input = Input(shape=shape)\n",
        "    x = generator(gan_input)\n",
        "    gan_output = discriminator(x)\n",
        "    gan = Model(inputs=gan_input, outputs=[x,gan_output])\n",
        "    gan.compile(loss=[vgg_loss, \"binary_crossentropy\"],\n",
        "                loss_weights=[1., 1e-3],\n",
        "                optimizer=optimizer)\n",
        "\n",
        "    return gan\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def train(epochs, batch_size, input_dir, output_dir, model_save_dir, number_of_images, train_test_ratio):\n",
        "    \n",
        "    x_train_lr, x_train_hr, x_test_lr, x_test_hr = load_training_data(input_dir, '.jpg', number_of_images, train_test_ratio) \n",
        "    loss = VGG_LOSS(image_shape)  \n",
        "    \n",
        "    batch_count = int(x_train_hr.shape[0] / batch_size)\n",
        "    shape = (image_shape[0]//downscale_factor, image_shape[1]//downscale_factor, image_shape[2])\n",
        "\n",
        "    #sess = tf.compat.v1.Session()\n",
        "    #graph = tf.compat.v1.get_default_graph()\n",
        "\n",
        "    \n",
        "    loss = VGG_LOSS(shape)  \n",
        "\n",
        "    epp = 2550\n",
        "\n",
        "    #with graph.as_default():\n",
        "      #tf.compat.v1.keras.backend.set_session(sess)\n",
        "    generator = load_model('/content/model/gen_model%d.h5' % epp , custom_objects={'vgg_loss': loss.vgg_loss})\n",
        "      #generator = Generator(shape).generator()\n",
        "    \n",
        "    loss = VGG_LOSS(image_shape)  \n",
        "\n",
        "    #with graph.as_default():\n",
        "      #tf.compat.v1.keras.backend.set_session(sess)\n",
        "    discriminator = load_model('/content/model/dis_model%d.h5' % epp , custom_objects={'vgg_loss': loss.vgg_loss})\n",
        "      #discriminator = Discriminator(image_shape).discriminator()\n",
        "\n",
        "    optimizer = get_optimizer()\n",
        "    generator.compile(loss=loss.vgg_loss, optimizer=optimizer)\n",
        "    discriminator.compile(loss=\"binary_crossentropy\", optimizer=optimizer)\n",
        "    \n",
        "    gan = get_gan_network(discriminator, shape, generator, optimizer, loss.vgg_loss)\n",
        "    \n",
        "    loss_file = open(model_save_dir + 'losses.txt' , 'w+')\n",
        "    loss_file.close()\n",
        "\n",
        "    for e in range(epp + 1, epochs+1):\n",
        "        print ('-'*15, 'Epoch %d' % e, '-'*15)\n",
        "        discriminator_loss = 0.0\n",
        "        gan_loss = 0.0\n",
        "        for _ in tqdm(range(batch_count)):\n",
        "\n",
        "            #print('----****----' )\n",
        "\n",
        "            \n",
        "            rand_nums = np.random.randint(0, x_train_hr.shape[0], size=batch_size)\n",
        "            \n",
        "            image_batch_hr = x_train_hr[rand_nums]\n",
        "            image_batch_lr = x_train_lr[rand_nums]\n",
        "            #print(image_batch_lr.shape[0],' ',image_batch_lr.shape[1],' ',image_batch_lr.shape[2])\n",
        "            #with graph.as_default():\n",
        "              #tf.compat.v1.keras.backend.set_session(sess)\n",
        "            generated_images_sr = generator.predict(image_batch_lr)\n",
        "\n",
        "            real_data_Y = np.ones(batch_size) - np.random.random_sample(batch_size)*0.2\n",
        "\n",
        "            fake_data_Y = np.random.random_sample(batch_size)*0.2\n",
        "\n",
        "            #print(generated_images_sr.shape[0],' ',generated_images_sr.shape[1],' ',generated_images_sr.shape[2])\n",
        "            #print(fake_data_Y.shape[0])\n",
        "\n",
        "            \n",
        "            discriminator.trainable = True\n",
        "            \n",
        "            #with graph.as_default():\n",
        "              #tf.compat.v1.keras.backend.set_session(sess)\n",
        "              #model.predict(...)\n",
        "            d_loss_real = discriminator.train_on_batch(image_batch_hr, real_data_Y)\n",
        "            #with graph.as_default():\n",
        "              #tf.compat.v1.keras.backend.set_session(sess)\n",
        "              #model.predict(...)\n",
        "            d_loss_fake = discriminator.train_on_batch(generated_images_sr, fake_data_Y)\n",
        "            discriminator_loss = 0.5 * np.add(d_loss_fake, d_loss_real)\n",
        "            \n",
        "            rand_nums = np.random.randint(0, x_train_hr.shape[0], size=batch_size)\n",
        "            image_batch_hr = x_train_hr[rand_nums]\n",
        "            image_batch_lr = x_train_lr[rand_nums]\n",
        "\n",
        "            gan_Y = np.ones(batch_size) - np.random.random_sample(batch_size)*0.2\n",
        "            discriminator.trainable = False\n",
        "            gan_loss = gan.train_on_batch(image_batch_lr, [image_batch_hr,gan_Y])\n",
        "            \n",
        "            \n",
        "        print(\"discriminator_loss : %f\" % discriminator_loss)\n",
        "        print(\"gan_loss : \", gan_loss)\n",
        "        gan_loss = str(gan_loss)\n",
        "        \n",
        "        loss_file = open(model_save_dir + 'losses.txt' , 'a')\n",
        "        loss_file.write('epoch%d : gan_loss = %s ; discriminator_loss = %f\\n' %(e, gan_loss, discriminator_loss) )\n",
        "        loss_file.close()\n",
        "\n",
        "        if e == 1 or e % 5 == 0:\n",
        "            plot_generated_images(output_dir, e, generator, x_test_hr, x_test_lr)\n",
        "        if e:\n",
        "            #tf.compat.v1.enable_eager_execution()\n",
        "            #with graph.as_default():\n",
        "             # tf.compat.v1.keras.backend.set_session(sess)\n",
        "            save_model(generator ,model_save_dir + 'gen_model%d.h5' % e)\n",
        "            #with graph.as_default():\n",
        "             # tf.compat.v1.keras.backend.set_session(sess)\n",
        "            save_model(discriminator ,model_save_dir + 'dis_model%d.h5' % e)\n",
        "            #tf.compat.v1.disable_eager_execution()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wcRz40MCfDy3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ba97f4f9-8fc9-44b6-cb80-64a1a9e112b1"
      },
      "source": [
        "epochs = 4000\n",
        "batch_size = 8\n",
        "input_dir = '/content/cocodataset/train2017'\n",
        "output_dir = '/content/cocodataset/train2017_output/'\n",
        "model_save_dir = '/content/model/'\n",
        "number_of_images = 2000\n",
        "train_test_ratio = 0.98\n",
        "train(epochs, batch_size, input_dir, output_dir, model_save_dir, number_of_images, train_test_ratio)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/scipy/misc/pilutil.py:482: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if issubdtype(ts, int):\n",
            "/usr/local/lib/python3.6/dist-packages/scipy/misc/pilutil.py:485: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
            "  elif issubdtype(type(size), float):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:245: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:186: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:199: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:206: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2018: The name tf.image.resize_nearest_neighbor is deprecated. Please use tf.compat.v1.image.resize_nearest_neighbor instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "80142336/80134624 [==============================] - 6s 0us/step\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3376: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/engine/saving.py:327: UserWarning: Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
            "  warnings.warn('Error in loading the saved optimizer '\n",
            "  0%|          | 0/245 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "--------------- Epoch 2535 ---------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 245/245 [04:11<00:00,  1.03s/it]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "discriminator_loss : 7.970380\n",
            "gan_loss :  [0.003922996, 0.002592718, 1.3302783]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/245 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "--------------- Epoch 2536 ---------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 245/245 [03:42<00:00,  1.10it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "discriminator_loss : 8.269907\n",
            "gan_loss :  [0.00323385, 0.0021492427, 1.0846074]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/245 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "--------------- Epoch 2537 ---------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 245/245 [03:42<00:00,  1.10it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "discriminator_loss : 8.169879\n",
            "gan_loss :  [0.004573779, 0.002890856, 1.6829228]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/245 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "--------------- Epoch 2538 ---------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 245/245 [03:42<00:00,  1.10it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "discriminator_loss : 7.615518\n",
            "gan_loss :  [0.003431424, 0.0020143455, 1.4170785]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/245 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "--------------- Epoch 2539 ---------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 245/245 [03:41<00:00,  1.10it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "discriminator_loss : 7.999873\n",
            "gan_loss :  [0.0030025768, 0.002131605, 0.8709716]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/245 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "--------------- Epoch 2540 ---------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 245/245 [03:41<00:00,  1.10it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "discriminator_loss : 8.063951\n",
            "gan_loss :  [0.0039309124, 0.0021607485, 1.770164]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/245 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "--------------- Epoch 2541 ---------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 245/245 [03:41<00:00,  1.10it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "discriminator_loss : 7.642528\n",
            "gan_loss :  [0.003169959, 0.0018931355, 1.2768233]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/245 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "--------------- Epoch 2542 ---------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 245/245 [03:41<00:00,  1.11it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "discriminator_loss : 7.770957\n",
            "gan_loss :  [0.0033071213, 0.002034568, 1.2725532]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/245 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "--------------- Epoch 2543 ---------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 245/245 [03:41<00:00,  1.11it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "discriminator_loss : 7.672709\n",
            "gan_loss :  [0.0041155806, 0.0023985824, 1.7169981]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/245 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "--------------- Epoch 2544 ---------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 245/245 [03:41<00:00,  1.10it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "discriminator_loss : 7.733688\n",
            "gan_loss :  [0.0030744297, 0.0021114154, 0.9630142]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/245 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "--------------- Epoch 2545 ---------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 245/245 [03:41<00:00,  1.10it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "discriminator_loss : 8.350562\n",
            "gan_loss :  [0.0034910417, 0.0016890669, 1.8019747]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/245 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "--------------- Epoch 2546 ---------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 245/245 [03:41<00:00,  1.10it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "discriminator_loss : 8.106840\n",
            "gan_loss :  [0.0039095976, 0.002320226, 1.5893714]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/245 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "--------------- Epoch 2547 ---------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 245/245 [03:41<00:00,  1.10it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "discriminator_loss : 8.005306\n",
            "gan_loss :  [0.0038196472, 0.0017887818, 2.0308652]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/245 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "--------------- Epoch 2548 ---------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 245/245 [03:41<00:00,  1.10it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "discriminator_loss : 8.505755\n",
            "gan_loss :  [0.002794648, 0.0017975287, 0.9971194]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/245 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "--------------- Epoch 2549 ---------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 245/245 [03:41<00:00,  1.10it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "discriminator_loss : 7.984324\n",
            "gan_loss :  [0.0034212805, 0.0022770162, 1.1442642]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/245 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "--------------- Epoch 2550 ---------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 245/245 [03:41<00:00,  1.10it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "discriminator_loss : 7.850189\n",
            "gan_loss :  [0.0034679845, 0.0017323288, 1.7356557]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/245 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "--------------- Epoch 2551 ---------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  2%|▏         | 6/245 [00:05<03:37,  1.10it/s]"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I7tmYAMWHpMp"
      },
      "source": [
        "val_input_dir = '/content/cocodataset/val2017'\n",
        "val_output_dir = '/content/cocodataset/val2017_output/'\n",
        "\n",
        "[x_test_lr, x_test_hr] = load_test_data_for_model(val_input_dir, '.jpg', 100)\n",
        "\n",
        "plot_test_generated_images_for_model(val_output_dir, generator, x_test_hr, x_test_lr)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A_PuItDNfDpY"
      },
      "source": [
        "test_input_dir = '/content/cocodataset/test2017'\n",
        "test_output_dir = '/content/cocodataset/test2017_output/'\n",
        "\n",
        "\n",
        "x_test_lr = load_test_data(test_input_dir, '.jpg', number_of_images = 100)\n",
        "\n",
        "plot_test_generated_images(test_output_dir, generator, x_test_lr)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QUD5N1FefDek",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "93beef6c-645a-4ecc-9599-3266a75057e0"
      },
      "source": [
        "model_save_dir = '/content/model/'\n",
        "\n",
        "image_shape = (80,60,3)\n",
        "\n",
        "\n",
        "loss = VGG_LOSS(image_shape)  \n",
        "model = load_model(model_save_dir + 'gen_model2000.h5' , custom_objects={'vgg_loss': loss.vgg_loss})\n",
        "\n",
        "val_input_dir = '/content/cocodataset/val2017'\n",
        "val_output_dir = '/content/val2017_output/'\n",
        "\n",
        "[x_test_lr, x_test_hr] = load_test_data_for_model(val_input_dir, '.jpg', 100)\n",
        "\n",
        "plot_test_generated_images_for_model(val_output_dir, model, x_test_hr, x_test_lr)\n",
        "\n",
        "\n",
        "test_input_dir = '/content/cocodataset/test2017'\n",
        "test_output_dir = '/content/cocodataset/test2017_output/'\n",
        "\n",
        "\n",
        "x_test_lr = load_test_data(test_input_dir, '.jpg', number_of_images = 100)\n",
        "\n",
        "plot_test_generated_images(test_output_dir, model, x_test_lr)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-3bf206cbe3f0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVGG_LOSS\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_save_dir\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'gen_model2000.h5'\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'vgg_loss'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvgg_loss\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'VGG_LOSS' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ACBpzlPDfDN0"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}